{"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.14","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":9251615,"sourceType":"datasetVersion","datasetId":5597172},{"sourceId":101778,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":85330,"modelId":109548},{"sourceId":101779,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":85331,"modelId":109549},{"sourceId":101781,"sourceType":"modelInstanceVersion","isSourceIdPinned":true,"modelInstanceId":85333,"modelId":109551}],"dockerImageVersionId":30761,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"source":"<a href=\"https://www.kaggle.com/code/mdrejwanurrahman/notebook8640634a91?scriptVersionId=194172004\" target=\"_blank\"><img align=\"left\" alt=\"Kaggle\" title=\"Open in Kaggle\" src=\"https://kaggle.com/static/images/open-in-kaggle.svg\"></a>","metadata":{},"cell_type":"markdown"},{"cell_type":"code","source":"import numpy as np\nimport matplotlib.pyplot as plt\nfrom scipy.interpolate import interp1d\n\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport seaborn as sns\nimport pandas as pd\nimport tensorflow as tf\nimport tensorflow_probability as tfp\nimport joblib","metadata":{"id":"8yjJr-iGvgdn","execution":{"iopub.status.busy":"2024-08-26T13:35:06.03159Z","iopub.execute_input":"2024-08-26T13:35:06.032252Z","iopub.status.idle":"2024-08-26T13:35:26.934266Z","shell.execute_reply.started":"2024-08-26T13:35:06.032199Z","shell.execute_reply":"2024-08-26T13:35:26.932917Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{"id":"8XGyoP3A9fek"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\nprint(\"TensorFlow version:\", tf.__version__)\nprint(\"TensorFlow Probability version:\", tfp.__version__)","metadata":{"id":"mgfxpLNkp--q","outputId":"f1f47a4f-6e14-45bc-8951-7bd95ada3fc1","execution":{"iopub.status.busy":"2024-08-26T13:32:35.50162Z","iopub.status.idle":"2024-08-26T13:32:35.502166Z","shell.execute_reply.started":"2024-08-26T13:32:35.501939Z","shell.execute_reply":"2024-08-26T13:32:35.501963Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip uninstall scikit-learn\n!pip install scikit-learn==1.2.2","metadata":{"id":"3-_bQegTpMTG","outputId":"c2a5f5a3-1a1c-45a4-eb7d-26e3681b981e"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"","metadata":{"id":"YC0m-5IQvj_z"}},{"cell_type":"code","source":"uploaded = files.upload()","metadata":{"id":"0GuxyVUrvkXs","outputId":"f17a8c54-0fc2-4579-f250-510e025d9b31","execution":{"iopub.status.busy":"2024-08-26T13:32:48.250748Z","iopub.execute_input":"2024-08-26T13:32:48.251227Z","iopub.status.idle":"2024-08-26T13:32:48.287765Z","shell.execute_reply.started":"2024-08-26T13:32:48.251185Z","shell.execute_reply":"2024-08-26T13:32:48.285681Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Choose the filename of the uploaded file\nfilename = '/kaggle/input/randata/OCT26_2022_M2_bLog0CFA-1deceleration_profile.txt'\n# Load the text file containing depth vs. deceleration values\ndata = np.loadtxt(filename)\ndepth = data[:, 0]\ndeceleration = data[:, 1]","metadata":{"id":"DTg46UHGvtUp","execution":{"iopub.status.busy":"2024-08-26T13:36:22.767679Z","iopub.execute_input":"2024-08-26T13:36:22.768969Z","iopub.status.idle":"2024-08-26T13:36:22.782074Z","shell.execute_reply.started":"2024-08-26T13:36:22.768897Z","shell.execute_reply":"2024-08-26T13:36:22.780428Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create an interpolation function\ninterpolation_function = interp1d(depth, deceleration, kind='nearest')\n\n# Define the depth intervals at 0.01 m increments\ndepth_interpolated = np.arange(min(depth), max(depth), 0.01)\n\n# Use the interpolation function to get deceleration values at these intervals\ndeceleration_interpolated = interpolation_function(depth_interpolated)\n\n","metadata":{"id":"W0FY99Nevyi-","execution":{"iopub.status.busy":"2024-08-26T13:36:28.764627Z","iopub.execute_input":"2024-08-26T13:36:28.765139Z","iopub.status.idle":"2024-08-26T13:36:28.774594Z","shell.execute_reply.started":"2024-08-26T13:36:28.765097Z","shell.execute_reply":"2024-08-26T13:36:28.772947Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Define the desired shape (211,)\ndesired_shape = (211,)\n\n# Calculate the number of zeros needed to pad\nzeros_to_add = desired_shape[0] - deceleration_interpolated.shape[0]\n\n# Pad the original array with zeros to achieve the desired shape\npadded_array = np.pad(deceleration_interpolated, (0, zeros_to_add), 'constant')\npadded_array=padded_array.reshape(1,211)","metadata":{"id":"Ap2bXT0pwRwL","execution":{"iopub.status.busy":"2024-08-26T13:36:32.43286Z","iopub.execute_input":"2024-08-26T13:36:32.433797Z","iopub.status.idle":"2024-08-26T13:36:32.44102Z","shell.execute_reply.started":"2024-08-26T13:36:32.433746Z","shell.execute_reply":"2024-08-26T13:36:32.439743Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"\n# Load the saved model\nloaded_rf_model = joblib.load('/kaggle/input/randomfor/scikitlearn/default/1/random_forest_model.joblib')\n\n# Now 'loaded_rf_model' contains the Random Forest model, and you can use it for predictions.\nmax_dec = np.max(padded_array, axis=1)\npd = np.count_nonzero(padded_array, axis=1)\npredRF=np.column_stack((max_dec,pd))\nclass_probs = loaded_rf_model.predict_proba(predRF)","metadata":{"id":"T5svUDpowUj0","execution":{"iopub.status.busy":"2024-08-26T13:39:09.497029Z","iopub.execute_input":"2024-08-26T13:39:09.497593Z","iopub.status.idle":"2024-08-26T13:39:10.04016Z","shell.execute_reply.started":"2024-08-26T13:39:09.497547Z","shell.execute_reply":"2024-08-26T13:39:10.038932Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sklearn\nimport joblib\n\nprint('scikit-learn version:', sklearn.__version__)\nprint('joblib version:', joblib.__version__)\n","metadata":{"id":"DDEecoDBAWB_","outputId":"a0f99542-cacb-46ba-bfbe-2610eb02ef92"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"class_probs","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:42:16.659831Z","iopub.execute_input":"2024-08-26T13:42:16.660295Z","iopub.status.idle":"2024-08-26T13:42:16.670804Z","shell.execute_reply.started":"2024-08-26T13:42:16.660254Z","shell.execute_reply":"2024-08-26T13:42:16.669206Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Original array with 4 values that sum up to 1\noriginal_array = np.array(class_probs)\n\n# Calculate the sum of the original array\noriginal_sum = np.sum(original_array)\n\n# Scale the array to sum up to 0.7\ndesired_sum = 0.6\npad=0.1\nscaled_array = (original_array / original_sum) * desired_sum\nprior=scaled_array+pad\nprint(prior)\nclasses = ['Class 1','Class 2','Class 3','Class 4']\n# plt.bar(classes,np.squeeze(prior))","metadata":{"id":"JPSgD3-VwmvB","outputId":"e153afea-37d3-4462-d39a-6c6e1f73f5af","execution":{"iopub.status.busy":"2024-08-26T13:39:24.819261Z","iopub.execute_input":"2024-08-26T13:39:24.81972Z","iopub.status.idle":"2024-08-26T13:39:24.829916Z","shell.execute_reply.started":"2024-08-26T13:39:24.819663Z","shell.execute_reply":"2024-08-26T13:39:24.828238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Load the saved model\n\n# from tensorflow.keras.models import load_model\n# loaded_model = tf.saved_model.load('/content/drive/MyDrive/Journal Paper 1/main_folder')\n\nscaler = joblib.load('/kaggle/input/scale/scikitlearn/default/1/scaler_fit.joblib')\n\npred_in_scaled = scaler.transform(padded_array.reshape(-1, 1)).reshape(padded_array.shape)\npred_in_scaled = np.reshape(pred_in_scaled,[pred_in_scaled.shape[0],pred_in_scaled.shape[1],1])\n# likelihood=loaded_model.predict(pred_in_scaled)\n","metadata":{"id":"hoRQn8kl4IgD","outputId":"bf343771-a7c9-4ce3-d4e5-a27152b47152","execution":{"iopub.status.busy":"2024-08-26T13:41:27.207245Z","iopub.execute_input":"2024-08-26T13:41:27.207753Z","iopub.status.idle":"2024-08-26T13:41:27.218544Z","shell.execute_reply.started":"2024-08-26T13:41:27.207684Z","shell.execute_reply":"2024-08-26T13:41:27.2172Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import tensorflow as tf\nimport tensorflow_probability as tfp\n\n# Define the kernel divergence function\ndef kernel_divergence_fn(q, p, _):\n    return tfp.distributions.kl_divergence(q, p) / 866.0\n\n# Model building\nclass BayesianConv1DModel(tf.Module):\n    def __init__(self, name=None):\n        super().__init__(name=name)\n        self.conv1 = tfp.layers.Convolution1DFlipout(32, kernel_size=3, activation='relu', \n                                                     kernel_divergence_fn=kernel_divergence_fn, \n                                                     padding='VALID')\n        self.conv2 = tfp.layers.Convolution1DFlipout(64, kernel_size=3, activation='relu', \n                                                     kernel_divergence_fn=kernel_divergence_fn, \n                                                     padding='VALID')\n        self.flatten = tf.keras.layers.Flatten()\n        self.dense1 = tfp.layers.DenseFlipout(1024, activation='relu', kernel_divergence_fn=kernel_divergence_fn)\n        self.dense2 = tfp.layers.DenseFlipout(64, activation='relu', kernel_divergence_fn=kernel_divergence_fn)\n        self.dense3 = tfp.layers.DenseFlipout(4, activation='softmax', kernel_divergence_fn=kernel_divergence_fn)\n\n    def __call__(self, x):\n        x = self.conv1(x)\n        x = self.conv2(x)\n        x = self.flatten(x)\n        x = self.dense1(x)\n        x = self.dense2(x)\n        x = self.dense3(x)\n        return x\n\n# Instantiate the model\nmodel = BayesianConv1DModel()\n\n# Define loss function\ndef loss_fn(labels, predictions):\n    return tf.reduce_mean(tf.keras.losses.categorical_crossentropy(labels, predictions))\n\n# Define the training step\ndef train_step(model, inputs, labels, optimizer):\n    with tf.GradientTape() as tape:\n        predictions = model(inputs)\n        loss = loss_fn(labels, predictions)\n    gradients = tape.gradient(loss, model.trainable_variables)\n    optimizer.apply_gradients(zip(gradients, model.trainable_variables))\n    return loss\n\n# # Example training loop\n# optimizer = tf.keras.optimizers.Adam()\n# for epoch in range(epochs):\n#     for inputs, labels in dataset:\n#         loss = train_step(model, inputs, labels, optimizer)\n#     print(f\"Epoch {epoch}, Loss: {loss.numpy()}\")","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:59:41.316557Z","iopub.execute_input":"2024-08-26T13:59:41.31708Z","iopub.status.idle":"2024-08-26T13:59:41.343855Z","shell.execute_reply.started":"2024-08-26T13:59:41.317036Z","shell.execute_reply":"2024-08-26T13:59:41.342092Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Create a new model instance\nmodel23 = BayesianConv1DModel()\n\n# Restore the weights\nlatest_checkpoint = tf.train.latest_checkpoint('/kaggle/input/finmodel/tensorflow2/default/1')\ncheckpoint.restore(latest_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:59:45.556778Z","iopub.execute_input":"2024-08-26T13:59:45.557266Z","iopub.status.idle":"2024-08-26T13:59:45.582899Z","shell.execute_reply.started":"2024-08-26T13:59:45.557224Z","shell.execute_reply":"2024-08-26T13:59:45.580865Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import numpy as np\n\n# Function to predict new data\ndef predict(model, new_data):\n    \"\"\"\n    Generates predictions from the model for the given new data.\n\n    Args:\n    model: The trained Bayesian neural network model.\n    new_data: A NumPy array or a TensorFlow tensor of new data to predict.\n\n    Returns:\n    A NumPy array of predictions.\n    \"\"\"\n    # Ensure the input is a TensorFlow tensor\n    new_data = tf.convert_to_tensor(new_data, dtype=tf.float32)\n\n    # Perform a forward pass and obtain the logits\n    logits = model(new_data)\n\n    # Since the last layer uses softmax, the output will be the probabilities\n    probabilities = tf.nn.softmax(logits)\n\n    # Optionally, you can obtain the class predictions directly\n#     class_predictions = tf.argmax(logits, axis=1)\n\n    return probabilities.numpy()  # Convert probabilities to NumPy array for easier handling\n\n# Example usage\n# Assuming `X_new` is your new dataset ready to be predicted\n# X_new = np.random.random((10, sequence_length, channels))  # Dummy data for illustration\n# predictions = predict(model, X_new)\n# print(predictions)","metadata":{"id":"EZP-H92TYBns","execution":{"iopub.status.busy":"2024-08-26T13:59:48.381336Z","iopub.execute_input":"2024-08-26T13:59:48.381901Z","iopub.status.idle":"2024-08-26T13:59:48.39098Z","shell.execute_reply.started":"2024-08-26T13:59:48.381852Z","shell.execute_reply":"2024-08-26T13:59:48.389312Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model23","metadata":{"execution":{"iopub.status.busy":"2024-08-26T13:51:47.355562Z","iopub.execute_input":"2024-08-26T13:51:47.35607Z","iopub.status.idle":"2024-08-26T13:51:47.365497Z","shell.execute_reply.started":"2024-08-26T13:51:47.356027Z","shell.execute_reply":"2024-08-26T13:51:47.364049Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Example usage\n# Assuming `X_new` is your new dataset ready to be predicted\n# X_new = np.random.random((10, sequence_length, channels))  # Dummy data for illustration\npredictions = predict(model23, pred_in_scaled)\nclass_predictions = tf.argmax(predictions, axis=1)\nprint(predictions)\nprint(class_predictions)","metadata":{"id":"a3Yl9dG7YDKu","outputId":"f9fe267d-c9ed-48c5-a303-d76e76847c33","execution":{"iopub.status.busy":"2024-08-26T14:00:32.173559Z","iopub.execute_input":"2024-08-26T14:00:32.174179Z","iopub.status.idle":"2024-08-26T14:00:33.151784Z","shell.execute_reply.started":"2024-08-26T14:00:32.17413Z","shell.execute_reply":"2024-08-26T14:00:33.150165Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tensorflow.keras.models import load_model\n\n# Load the model\nmodel = tf.saved_model.load('/content/drive/MyDrive/Journal Paper 1/main_folder')\n","metadata":{"id":"FWKu6AS6AQG0"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predictions*prior","metadata":{"id":"VBoQY2wZW17_","execution":{"iopub.status.busy":"2024-08-26T14:01:58.424412Z","iopub.execute_input":"2024-08-26T14:01:58.424969Z","iopub.status.idle":"2024-08-26T14:01:58.435857Z","shell.execute_reply.started":"2024-08-26T14:01:58.42492Z","shell.execute_reply":"2024-08-26T14:01:58.433825Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"ss =[]\n# n= int(input())\n\n\nc = [1,2,3,4]\nplt.figure()\nfig, ax = plt.subplots(1,2)\n\nfor i in range(0,30):\n  s = loaded_model.predict(pred_in_scaled,verbose = 1)\n  post=((prior)*s)\n  final_s = post/np.sum(post)\n  ss.append(final_s)\n  ax[1].scatter(c,final_s,c=\"blue\",alpha=0.1)\n# ss=np.array(ss)\n# sss = pd.DataFrame(np.squeeze(ss))\nsss = np.squeeze(ss)\nax[1].boxplot(sss)\nax[1].set_xticklabels(classes)\n# ax[1].text(1.8, -0.25, 'Actual Result: Class '+str(y_train[n]+1), color='red')\n\n\nax[0].plot(deceleration,depth*100, label=filename)\nax[0].invert_yaxis()\nax[0].set_ylabel(\"Depth [cm]\")\nax[0].set_xlabel(\"Deceleration[g]\")","metadata":{"id":"GP7apsqn4nFj","outputId":"c573dcbc-292a-4c62-d0d1-8f358ba760ae"},"execution_count":null,"outputs":[]}]}